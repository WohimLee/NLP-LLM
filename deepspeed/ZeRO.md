# ZeRO (Zero Redundancy Optimizer)

DeepSpeed 的 ZeRO (Zero Redundancy Optimizer) 优化技术分为三个不同的阶段（stages），每个阶段在内存优化和计算效率上都有不同的侧重点。

### Stage 1: 优化器状态分片（Optimizer State Partitioning）
- 主要功能: 在 Stage 1 中，DeepSpeed 通过将优化器状态（如动量和二阶矩）分布在所有 GPU 上，从而减少每个 GPU 上的内存占用。
- 如何工作: 在标准的分布式训练中，每个 GPU 都会维护完整的优化器状态。而在 ZeRO Stage 1 中，优化器状态被分片，即每个 GPU 只存储一部分优化器状态。这样，内存消耗随 GPU 数量的增加而减少，使得在每个 GPU 上可以训练更大的模型。
- 优势: 通过减小优化器状态的内存占用，Stage 1 允许训练更大规模的模型，并在一定程度上提升训练效率。


### Stage 2: 梯度分片（Gradient Partitioning）
- 主要功能: Stage 2 在 Stage 1 的基础上进一步优化，除了优化器状态外，还对梯度进行分片。
- 如何工作: 在这一阶段，梯度计算完成后，不会将完整的梯度保存在每个 GPU 上，而是将其分割并分布在所有 GPU 上。每个 GPU 只负责更新自己所持有的参数和梯度分片。
- 优势: 通过对梯度分片，Stage 2 能够进一步减少内存占用，使得内存需求降低到与模型大小成线性关系。这使得模型的训练规模进一步扩大，并且支持更大的有效批次大小。


### Stage 3: 参数分片（Parameter Partitioning）
- 主要功能: Stage 3 是 ZeRO 优化的最高阶段，它在前两个阶段的基础上，进一步对模型参数进行分片和分布管理
- 如何工作: 在 Stage 3 中，模型参数被分片到各个 GPU 上，并且在前向传播、反向传播和优化过程中，参数的分片和通信被巧妙地协调。这不仅减少了模型参数在各个 GPU 上的内存占用，而且还通过参数的异步加载和释放，进一步优化内存使用
- 优势: Stage 3 减少了每个 GPU 上的内存占用到极致，使得每个 GPU 只需要存储其计算所需的参数分片。这种策略极大地扩展了可以在给定硬件上训练的模型规模，并允许在不增加硬件的情况下训练超大规模模型。Stage 3 还支持 CPU 上的参数和优化器状态的卸载（offloading），进一步减少 GPU 内存负担


### 总结
Stage 1 主要减少优化器状态的内存占用，适合于那些内存主要被优化器状态占用的模型。
Stage 2 在此基础上进一步减少了梯度的内存占用，适合于希望通过更大批次进行训练的场景。
Stage 3 则最大化了内存的节约效果，适合于超大规模模型的训练，特别是当内存非常紧张时。
随着 ZeRO 优化阶段的推进，模型训练的可扩展性和内存效率逐步提高，使得能够在相对有限的硬件资源下，训练更大规模的深度学习模型。